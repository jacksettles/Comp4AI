{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0290656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch stuff\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import glob\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim\n",
    "\n",
    "# Compression modules\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from Comp4AI.notebooks.pysz.pysz import SZ\n",
    "import zfpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04ba458c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    # CUDA is available, you can proceed to use it\n",
    "    device = torch.device('cuda')\n",
    "    print('CUDA is available. Using GPU.')\n",
    "else:\n",
    "    # CUDA is not available, use CPU\n",
    "    device = torch.device('cpu')\n",
    "    print('CUDA is not available. Using CPU.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b4c481c",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    transforms.Resize((256,256))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d4d608a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = 'subclasses-tiny-imagenet/*/images/*.JPEG'\n",
    "jpeg_files = glob.glob(pattern, recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33855bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FineTuningDataset(Dataset):\n",
    "    def __init__(self, data, transform = resnet_transform):\n",
    "        '''class_dict = {'n02410509':347,\n",
    "                      'n02106662':235,\n",
    "                      'n07734744':947,\n",
    "                      'n07873807':963,\n",
    "                      'n07920052':967,\n",
    "                      'n09428293':978,\n",
    "                      'n01910747':107,\n",
    "                      'n01882714':105,\n",
    "                      'n04285008':817,\n",
    "                      'n04146614':779}'''\n",
    "        \n",
    "        class_dict = {'n02410509':0,\n",
    "                      'n02106662':1,\n",
    "                      'n07734744':2,\n",
    "                      'n07873807':3,\n",
    "                      'n07920052':4,\n",
    "                      'n09428293':5,\n",
    "                      'n01910747':6,\n",
    "                      'n01882714':7,\n",
    "                      'n04285008':8,\n",
    "                      'n04146614':9}\n",
    "        \n",
    "        data_and_labels = []\n",
    "        for i in range(len(data)):\n",
    "            file_path = data[i]\n",
    "        \n",
    "            # Split the file string\n",
    "            split_file = data[i].split('/')\n",
    "            class_wnid = split_file[1]\n",
    "            file_name = split_file[3]\n",
    "        \n",
    "            with Image.open(file_path) as img:\n",
    "            \n",
    "                # Convert grayscale images to RGB\n",
    "                if img.mode == 'L':\n",
    "                    img = img.convert('RGB')\n",
    "            \n",
    "                img_tensor = resnet_transform(img)\n",
    "            \n",
    "            data_and_labels.append((img_tensor, class_dict[class_wnid]))\n",
    "        \n",
    "        self.data = data_and_labels\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx][0]\n",
    "        target = self.data[idx][1]\n",
    "        \n",
    "        return sample, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "485cde24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune(model=None, train_loader=None, loss_func=None, model_name=None, num_epochs=5, optimizer=None, test_loader=None):\n",
    "    model = model.to(device)\n",
    "    highest_acc = 0\n",
    "    \n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        running_loss = 0.0\n",
    "        for step, (images, labels) in enumerate(train_loader):\n",
    "            model.train()   # set the model in training mode\n",
    "                \n",
    "            images = images.to(device) # move images and labels to GPU\n",
    "            labels = labels.to(device)\n",
    "                \n",
    "            optimizer.zero_grad() # Zero out gradients from last backprop\n",
    "                \n",
    "            outputs = model(images) # Pass images through the model\n",
    "            _, predicted = torch.max(outputs.data, 1) # Obtain indices of predictions\n",
    "                \n",
    "            train_loss = loss_func(outputs, labels) # Get the loss and backpropogate it\n",
    "            train_loss.backward()\n",
    "                \n",
    "            # Get some metrics\n",
    "            running_loss += train_loss\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum()\n",
    "            train_accuracy = 100 * (train_correct/train_total)\n",
    "                \n",
    "            if step % 5 == 0:\n",
    "                test_acc, test_loss = test(model=model, test_loader=test_loader, loss_func=loss_func)\n",
    "                print(f\"Epoch: {epoch}, Step: {step}\")\n",
    "                print(f\"\\tTrain Loss: {running_loss}, Train Accuracy: {train_accuracy}\")\n",
    "                print(f\"\\tTest Loss: {test_loss}, Test Accuracy: {test_acc}\")\n",
    "                print()\n",
    "                if test_acc > highest_acc:\n",
    "                    highest_acc = test_acc\n",
    "                    torch.save(model.state_dict(), f'{model_name}.pt')\n",
    "                \n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e6674f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model=None, test_loader=None, loss_func=None):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    \n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        for images, labels in test_loader:            \n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            test_loss = loss_func(outputs, labels)\n",
    "            total_loss += test_loss\n",
    "            \n",
    "            # Increment total number of observations seen by\n",
    "            # number of items in this batch\n",
    "            total += labels.size(0)\n",
    "\n",
    "            # Increment total number of correct predictions by\n",
    "            # number of correct predictions in this batch\n",
    "            correct += (predicted == labels).sum()\n",
    "            \n",
    "        accuracy = (100 * (correct/total))\n",
    "        accuracy = accuracy.item()\n",
    "        return accuracy, total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56db68e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_memory_usage(stage):\n",
    "    print(f\"{stage} - Memory allocated: {torch.cuda.memory_allocated() / (1024 ** 2):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c49b591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_intermediate_results(model=None, \n",
    "                                 mode=\"train\", layer=0, tolerance=1e-3,\n",
    "                                 model_name=None, criterion=None, optimizer=None,\n",
    "                                 train_loader=None, test_loader=None, num_epochs=5):\n",
    "    def zfpy_compress_output(module, input, output):\n",
    "        if mode != \"train\":\n",
    "            output = output.cpu().numpy() # For testing\n",
    "        else:\n",
    "            output = output.cpu().detach().numpy() # For training\n",
    "        compressed_data = zfpy.compress_numpy(output, tolerance=tolerance)\n",
    "    #     compressed_data = zfpy.compress_numpy(output, rate=8)\n",
    "        decompressed_array = zfpy.decompress_numpy(compressed_data)\n",
    "        output_dec = torch.from_numpy(decompressed_array).to(device)\n",
    "        return output_dec\n",
    "\n",
    "    if layer == 0:\n",
    "        hook = model.maxpool.register_forward_hook(zfpy_compress_output)\n",
    "    elif layer == 1:\n",
    "        hook = model.layer1[-1].register_forward_hook(zfpy_compress_output)\n",
    "    elif layer == 2:\n",
    "        hook = model.layer2[-1].register_forward_hook(zfpy_compress_output)\n",
    "    elif layer == 3:\n",
    "        hook = model.layer3[-1].register_forward_hook(zfpy_compress_output)\n",
    "    elif layer == 4:\n",
    "        hook = model.layer4[-1].register_forward_hook(zfpy_compress_output)\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "    \n",
    "    if mode == \"train\":\n",
    "        fine_tune(model=model, train_loader=train_loader, loss_func=criterion, model_name=model_name, optimizer=optimizer,\n",
    "                 test_loader=test_loader, num_epochs=num_epochs)\n",
    "    else:\n",
    "        accuracy, test_loss = test(model=model, test_loader=test_loader, loss_func=criterion)\n",
    "        \n",
    "    end_time = time.perf_counter()\n",
    "    total_time = end_time - start_time\n",
    "    minutes, seconds = divmod(total_time, 60)\n",
    "    hook.remove()\n",
    "    \n",
    "    if mode == \"train\":\n",
    "        print()\n",
    "        print(\"-------------------\")\n",
    "        print(\"Finished training!!\")\n",
    "        print(\"Layer: {}, Tolerance: {}, Total training time: {}:{}\".format(layer, tolerance, int(minutes), int(seconds)))\n",
    "        print(\"-------------------\")\n",
    "        return tolerance, int(minutes), int(seconds)\n",
    "    else:\n",
    "        print(\"Accuracy with zfpy: {:.2f}%\\tTime spent: {}:{}\".format(accuracy, int(minutes), int(seconds)))\n",
    "        return accuracy, int(minutes), int(seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3dd90493",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training(tolerances, training_times, layer):\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(tolerances, training_times, width=0.05, log=True)\n",
    "    \n",
    "    plt.xlabel('Tolerance Levels')\n",
    "    plt.ylabel('Training Time (minutes)')\n",
    "    \n",
    "    # Adding a title\n",
    "    plt.title(f'Training Time vs Tolerance Levels for layer {layer}')\n",
    "\n",
    "    # Set x-axis to log scale for better readability\n",
    "    plt.xscale('log')\n",
    "\n",
    "    plt.savefig(f'comp_training_images/layer{layer}_training_time_vs_tolerance.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    # Display the chart\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c73ac368",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_testing(tolerances, accuracies, layer):\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(tolerances, accuracies, width=0.05, log=True)\n",
    "    \n",
    "    plt.xlabel('Tolerance Levels')\n",
    "    plt.ylabel('Accuracy')\n",
    "    \n",
    "    # Adding a title\n",
    "    plt.title(f'Accuracy vs Tolerance Levels during training for layer: {layer}')\n",
    "\n",
    "    # Set x-axis to log scale for better readability\n",
    "    plt.xscale('log')\n",
    "\n",
    "    plt.savefig(f'comp_training_images/layer{layer}_accuracy_vs_tolerance.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4c50d792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--tolerance'], dest='tolerance', nargs=None, const=None, default=0.001, type=None, choices=[1, 0.1, 0.01, 0.001, 0.0001], help='Tolerance you want to pass through to the compression algorithm', metavar=None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--mode', default=\"train\", choices=[\"train\", \"test\"], help=\"Compress during training or testing\")\n",
    "parser.add_argument('--layer', default=0, choices=[0, 1, 2, 3, 4], help=\"Which stage of the model do you want to compress the intermediate results from\")\n",
    "parser.add_argument('--model_name', choices=['zfpy', 'sz3'], help='name you want to save the model to')\n",
    "parser.add_argument('--tolerance', default=1e-3, choices=[1, 1e-1, 1e-2, 1e-3, 1e-4], help=\"Tolerance you want to pass through to the compression algorithm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "30f85760",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "batch_size = 128\n",
    "\n",
    "data = FineTuningDataset(jpeg_files)\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "27d6380d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Step: 0\n",
      "\tTrain Loss: 2.310154676437378, Train Accuracy: 10.15625\n",
      "\tTest Loss: 18.695138931274414, Test Accuracy: 5.800000190734863\n",
      "\n",
      "Epoch: 1, Step: 5\n",
      "\tTrain Loss: 12.940238952636719, Train Accuracy: 38.020835876464844\n",
      "\tTest Loss: 16.452285766601562, Test Accuracy: 50.80000305175781\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [36], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrial\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;66;03m#args.model_name\u001b[39;00m\n\u001b[1;32m     17\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m model_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_tolerance_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(tol)\n\u001b[0;32m---> 19\u001b[0m _, minutes, seconds \u001b[38;5;241m=\u001b[39m \u001b[43mcompress_intermediate_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresnet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#args.mode,\u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m times\u001b[38;5;241m.\u001b[39mappend(minutes)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Load the model you just saved to test it now\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [26], line 30\u001b[0m, in \u001b[0;36mcompress_intermediate_results\u001b[0;34m(model, mode, layer, tolerance, model_name, criterion, optimizer, train_loader, test_loader, num_epochs)\u001b[0m\n\u001b[1;32m     27\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 30\u001b[0m     \u001b[43mfine_tune\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m             \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m     accuracy, test_loss \u001b[38;5;241m=\u001b[39m test(model\u001b[38;5;241m=\u001b[39mmodel, test_loader\u001b[38;5;241m=\u001b[39mtest_loader, loss_func\u001b[38;5;241m=\u001b[39mcriterion)\n",
      "Cell \u001b[0;32mIn [23], line 17\u001b[0m, in \u001b[0;36mfine_tune\u001b[0;34m(model, train_loader, loss_func, model_name, num_epochs, optimizer, test_loader)\u001b[0m\n\u001b[1;32m     13\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad() \u001b[38;5;66;03m# Zero out gradients from last backprop\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Pass images through the model\u001b[39;00m\n\u001b[1;32m     18\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# Obtain indices of predictions\u001b[39;00m\n\u001b[1;32m     20\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m loss_func(outputs, labels) \u001b[38;5;66;03m# Get the loss and backpropogate it\u001b[39;00m\n",
      "File \u001b[0;32m/apps/eb/PyTorch/1.12.1-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/apps/eb/torchvision/0.13.1-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torchvision/models/resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/apps/eb/torchvision/0.13.1-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torchvision/models/resnet.py:271\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    269\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(x)\n\u001b[1;32m    270\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[0;32m--> 271\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaxpool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(x)\n\u001b[1;32m    274\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n",
      "File \u001b[0;32m/apps/eb/PyTorch/1.12.1-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/nn/modules/module.py:1151\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1150\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m-> 1151\u001b[0m         hook_result \u001b[38;5;241m=\u001b[39m \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1152\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m hook_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1153\u001b[0m             result \u001b[38;5;241m=\u001b[39m hook_result\n",
      "Cell \u001b[0;32mIn [26], line 12\u001b[0m, in \u001b[0;36mcompress_intermediate_results.<locals>.zfpy_compress_output\u001b[0;34m(module, input, output)\u001b[0m\n\u001b[1;32m     10\u001b[0m     compressed_data \u001b[38;5;241m=\u001b[39m zfpy\u001b[38;5;241m.\u001b[39mcompress_numpy(output, tolerance\u001b[38;5;241m=\u001b[39mtolerance)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#     compressed_data = zfpy.compress_numpy(output, rate=8)\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     decompressed_array \u001b[38;5;241m=\u001b[39m \u001b[43mzfpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecompress_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompressed_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     output_dec \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(decompressed_array)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output_dec\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "args = parser.parse_args()\n",
    "layers = [0, 1, 2, 3, 4]\n",
    "tols = [1, 1e-1, 1e-2, 1e-3, 1e-4]\n",
    "times = []\n",
    "accuracies = []\n",
    "\n",
    "for layer in layers:\n",
    "    for tol in tols:\n",
    "        resnet = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "        num_classes = 10\n",
    "        resnet.fc = nn.Linear(2048, num_classes)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(resnet.fc.parameters(), lr=0.001)\n",
    "\n",
    "        model_name = args.model_name\n",
    "        model_name = \"models/\" + model_name + \"_tolerance_\" + str(tol)\n",
    "\n",
    "        _, minutes, seconds = compress_intermediate_results(model=resnet,\n",
    "                                                            mode=args.mode,\n",
    "                                                            layer=layer,\n",
    "                                                            tolerance=tol,\n",
    "                                                            model_name=model_name,\n",
    "                                                            criterion=criterion,\n",
    "                                                            optimizer=optimizer,\n",
    "                                                            train_loader=train_loader,\n",
    "                                                            test_loader=test_loader,\n",
    "                                                            num_epochs=num_epochs)\n",
    "        times.append(minutes)\n",
    "\n",
    "        # Load the model you just saved to test it now\n",
    "        resnet.load_state_dict(torch.load(f'{model_name}.pt'))\n",
    "\n",
    "        accuracy, test_loss = test(model=resnet, test_loader=test_loader, loss_func=criterion)\n",
    "        accuracies.append(accuracy)\n",
    "    \n",
    "    plot_training(tols, times, layer)\n",
    "    plot_testing(tols, accuracies, layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae54b041",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b938cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
