{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dcb3fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch stuff\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import glob\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim\n",
    "\n",
    "# Compression modules\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from Comp4AI.notebooks.pysz.pysz import SZ\n",
    "import zfpy\n",
    "\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08e5ba6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    # CUDA is available, you can proceed to use it\n",
    "    device = torch.device('cuda')\n",
    "    print('CUDA is available. Using GPU.')\n",
    "else:\n",
    "    # CUDA is not available, use CPU\n",
    "    device = torch.device('cpu')\n",
    "    print('CUDA is not available. Using CPU.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77c077c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    transforms.Resize((256,256))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e828be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "resnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ef0bbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "resnet.fc = nn.Linear(2048, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3203618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet.load_state_dict(torch.load(\"finetuned_resnet.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2467afaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = 'subclasses-tiny-imagenet/*/images/*.JPEG'\n",
    "jpeg_files = glob.glob(pattern, recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f81fe3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FineTuningDataset(Dataset):\n",
    "    def __init__(self, data, transform = resnet_transform):\n",
    "        '''class_dict = {'n02410509':347,\n",
    "                      'n02106662':235,\n",
    "                      'n07734744':947,\n",
    "                      'n07873807':963,\n",
    "                      'n07920052':967,\n",
    "                      'n09428293':978,\n",
    "                      'n01910747':107,\n",
    "                      'n01882714':105,\n",
    "                      'n04285008':817,\n",
    "                      'n04146614':779}'''\n",
    "        \n",
    "        class_dict = {'n02410509':0,\n",
    "                      'n02106662':1,\n",
    "                      'n07734744':2,\n",
    "                      'n07873807':3,\n",
    "                      'n07920052':4,\n",
    "                      'n09428293':5,\n",
    "                      'n01910747':6,\n",
    "                      'n01882714':7,\n",
    "                      'n04285008':8,\n",
    "                      'n04146614':9}\n",
    "        \n",
    "        data_and_labels = []\n",
    "        for i in range(len(data)):\n",
    "            file_path = data[i]\n",
    "        \n",
    "            # Split the file string\n",
    "            split_file = data[i].split('/')\n",
    "            class_wnid = split_file[1]\n",
    "            file_name = split_file[3]\n",
    "        \n",
    "            with Image.open(file_path) as img:\n",
    "            \n",
    "                # Convert grayscale images to RGB\n",
    "                if img.mode == 'L':\n",
    "                    img = img.convert('RGB')\n",
    "            \n",
    "                img_tensor = resnet_transform(img)\n",
    "            \n",
    "            data_and_labels.append((img_tensor, class_dict[class_wnid]))\n",
    "        \n",
    "        self.data = data_and_labels\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx][0]\n",
    "        target = self.data[idx][1]\n",
    "        \n",
    "        return sample, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c593073e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = FineTuningDataset(jpeg_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a22fa44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8a670c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resnet.fc.parameters(), lr=0.001)\n",
    "num_epochs = 10\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e85d6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54756a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune(model=None, train_loader=None, loss_func=None, model_name=None):\n",
    "    model = model.to(device)\n",
    "    highest_acc = 0\n",
    "    \n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        running_loss = 0.0\n",
    "        for step, (images, labels) in enumerate(train_loader):\n",
    "            model.train()   # set the model in training mode\n",
    "                \n",
    "            images = images.to(device) # move images and labels to GPU\n",
    "            labels = labels.to(device)\n",
    "                \n",
    "            optimizer.zero_grad() # Zero out gradients from last backprop\n",
    "                \n",
    "            outputs = model(images) # Pass images through the model\n",
    "            _, predicted = torch.max(outputs.data, 1) # Obtain indices of predictions\n",
    "                \n",
    "            train_loss = loss_func(outputs, labels) # Get the loss and backpropogate it\n",
    "            train_loss.backward()\n",
    "                \n",
    "            # Get some metrics\n",
    "            running_loss += train_loss\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum()\n",
    "            train_accuracy = 100 * (train_correct/train_total)\n",
    "                \n",
    "            if step % 5 == 0:\n",
    "                test_acc, test_loss = test(model=model, test_loader=test_loader, loss_func=loss_func)\n",
    "                print(f\"Epoch: {epoch}, Step: {step}\")\n",
    "                print(f\"\\tTrain Loss: {running_loss}, Train Accuracy: {train_accuracy}\")\n",
    "                print(f\"\\tTest Loss: {test_loss}, Test Accuracy: {test_acc}\")\n",
    "                print()\n",
    "                if test_acc > highest_acc:\n",
    "                    highest_acc = test_acc\n",
    "                    torch.save(model.state_dict(), f'{model_name}.pt')\n",
    "                \n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf1df95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model=None, test_loader=None, loss_func=None):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    \n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        for images, labels in test_loader:            \n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            test_loss = loss_func(outputs, labels)\n",
    "            total_loss += test_loss\n",
    "            \n",
    "            # Increment total number of observations seen by\n",
    "            # number of items in this batch\n",
    "            total += labels.size(0)\n",
    "\n",
    "            # Increment total number of correct predictions by\n",
    "            # number of correct predictions in this batch\n",
    "            correct += (predicted == labels).sum()\n",
    "            \n",
    "        accuracy = (100 * (correct/total))\n",
    "        accuracy = accuracy.item()\n",
    "        return accuracy, total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48611fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine_tune(model=resnet, train_loader=train_loader, loss_func=criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8330cf87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy without compression: 10.20%\tTime spent: 0:10\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "\n",
    "accuracy, test_loss = test(model=resnet, test_loader=test_loader, loss_func=criterion)\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "total_time = end_time - start_time\n",
    "minutes, seconds = divmod(total_time, 60)\n",
    "\n",
    "print(\"Accuracy without compression: {:.2f}%\\tTime spent: {}:{}\".format(accuracy, int(minutes), int(seconds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7c07ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94362112"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "169ba8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare your data in numpy array format\n",
    "HOME=\"/home/jts75596/yuan_projects/feature_maps\"\n",
    "\n",
    "# init SZ (both SZ2 and SZ3 are supported)\n",
    "# Please change the path to the SZ dynamic library file in your system\n",
    "lib_extention = {\n",
    "    \"darwin\": \"libSZ3c.dylib\",\n",
    "    \"windows\": \"SZ3c.dll\",\n",
    "}.get(sys.platform, \"libSZ3c.so\")\n",
    "\n",
    "sz = SZ(\"{}/ExternalDependencies/SZ3/install/lib64/{}\".format(HOME,lib_extention))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08b8a29",
   "metadata": {},
   "source": [
    "## Register forward hook to catch the inermediate results, compress them, then decompress them, and see how it performs on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9eb200b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_memory_usage(stage):\n",
    "    print(f\"{stage} - Memory allocated: {torch.cuda.memory_allocated() / (1024 ** 2):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a78c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.to(device)\n",
    "resnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea6e682c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with SZ3: 92.20%\tTime spent: 0:30\n"
     ]
    }
   ],
   "source": [
    "# def SZ3_compress_output(module, input, output):\n",
    "#     output = output.cpu().numpy()\n",
    "#     data_cmpr, cmpr_ratio = sz.compress(output, 1, 0, 0.001, 0)\n",
    "#     data_dec = sz.decompress(data_cmpr, output.shape, output.dtype)\n",
    "#     output_dec = torch.from_numpy(data_dec).to(device)\n",
    "#     return output_dec\n",
    "    \n",
    "# hook = resnet.maxpool.register_forward_hook(SZ3_compress_output)\n",
    "\n",
    "# start_time = time.perf_counter()\n",
    "# accuracy, test_loss = test(model=resnet, test_loader=test_loader, loss_func=criterion)\n",
    "# end_time = time.perf_counter()\n",
    "# total_time = end_time - start_time\n",
    "# minutes, seconds = divmod(total_time, 60)\n",
    "\n",
    "# print(\"Accuracy with SZ3: {:.2f}%\\tTime spent: {}:{}\".format(accuracy, int(minutes), int(seconds)))\n",
    "# hook.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590ee2b8",
   "metadata": {},
   "source": [
    "### Layer 1 output takes the longest because intermediate results are largest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44581589",
   "metadata": {},
   "source": [
    "### Rate=8 achieves same quality, if not better, in less time than tolerance=1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffef754",
   "metadata": {},
   "source": [
    "### is tolerance=8 supposed to work so well???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41983483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with zfpy: 10.20%\tTime spent: 0:20\n"
     ]
    }
   ],
   "source": [
    "def compress_intermediate_results(mode=\"train\", layer=0, tolerance=1e-3, model_name=None):\n",
    "    def zfpy_compress_output(module, input, output):\n",
    "        if mode != \"train\":\n",
    "            output = output.cpu().numpy() # For testing\n",
    "        else:\n",
    "            output = output.cpu().detach().numpy() # For training\n",
    "        compressed_data = zfpy.compress_numpy(output, tolerance=tolerance)\n",
    "    #     compressed_data = zfpy.compress_numpy(output, rate=8)\n",
    "        decompressed_array = zfpy.decompress_numpy(compressed_data)\n",
    "        output_dec = torch.from_numpy(decompressed_array).to(device)\n",
    "        return output_dec\n",
    "\n",
    "    if layer == 0:\n",
    "        hook = resnet.maxpool.register_forward_hook(zfpy_compress_output)\n",
    "    elif layer == 1:\n",
    "        hook = resnet.layer1[-1].register_forward_hook(zfpy_compress_output)\n",
    "    elif layer == 2:\n",
    "        hook = resnet.layer2[-1].register_forward_hook(zfpy_compress_output)\n",
    "    elif layer == 3:\n",
    "        hook = resnet.layer3[-1].register_forward_hook(zfpy_compress_output)\n",
    "    elif layer == 4:\n",
    "        hook = resnet.layer4[-1].register_forward_hook(zfpy_compress_output)\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "    if mode == \"train\":\n",
    "        fine_tune(model=resnet, train_loader=train_loader, loss_func=criterion, model_name=model_name)\n",
    "    else:\n",
    "        accuracy, test_loss = test(model=resnet, test_loader=test_loader, loss_func=criterion)\n",
    "    end_time = time.perf_counter()\n",
    "    total_time = end_time - start_time\n",
    "    minutes, seconds = divmod(total_time, 60)\n",
    "    hook.remove()\n",
    "    \n",
    "    if mode == \"train\":\n",
    "        print()\n",
    "        print(\"-------------------\")\n",
    "        print(\"Finished training!!\")\n",
    "        print(\"Layer: {}, Tolerance: {}, Total training time: {}:{}\".format(layer, tolerance, int(minutes), int(seconds)))\n",
    "        print(\"-------------------\")\n",
    "    else:\n",
    "        print(\"Accuracy with zfpy: {:.2f}%\\tTime spent: {}:{}\".format(accuracy, int(minutes), int(seconds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa896b60",
   "metadata": {},
   "source": [
    "#### This block below will kill the kernel with 16 GB of memory, likely due to memory overflow issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe45b78",
   "metadata": {},
   "source": [
    "## Explore ways of compressing and decompressing without moving elements to the cpu and back. So need to find a way to compress and decompress tensors while they are on the gpu. Look at CuPy library for this..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138eebad",
   "metadata": {},
   "source": [
    "###### Might still have to move it to cpu to use CuPy though..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa46eaf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
